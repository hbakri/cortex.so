---
title: Overview
description: Cortex Overview.
slug: /
---

import OAICoverage from "@site/src/components/OAICoverage"

# Cortex

:::warning
ðŸš§ Cortex is under construction.
:::

![Cortex Cover Image](/img/docs/cortex-cover.png)

Cortex is a fast, cross-platform AI engine. Developers can use Cortex to build LLM apps or run model operations on-device. Cortex has a Docker and Ollama inspired CLI, and it can be used as a server or imported as a library.

Cortex currently supports 3 inference engines:

- [Llama.cpp](https://github.com/ggerganov/llama.cpp)
- [ONNX Runtime](https://github.com/microsoft/onnxruntime)
- [TensorRT-LLM](https://github.com/NVIDIA/TensorRT-LLM)

:::info
**Real-world Use**: Cortex powers [Jan](https://jan.ai), our on-device ChatGPT-alternative.

Cortex has been battle-tested across 1 million+ downloads and handles a variety of hardware configurations.
:::

## Roadmap

Cortex aims to be compatible with [OpenAI API](https://platform.openai.com/docs/api-reference).

Our goal is to make it easy for developers to provide on-device AI and to build more secure applications, using a fully open-source stack.

## OpenAI Equivalence

<OAICoverage /> 
